{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Edu\\\\Python\\\\MLOPS_projects\\\\mlops_nlp_summarizer\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMEXPR_MAX_THREADS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Edu\\\\Python\\\\MLOPS_projects\\\\mlops_nlp_summarizer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class CredentialsConfig:\n",
    "    MLFLOW_TRACKING_URI: str\n",
    "    MLFLOW_TRACKING_USERNAME: str\n",
    "    MLFLOW_TRACKING_PASSWORD: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlops_NLP_Text_Summarization.constants import *\n",
    "from mlops_NLP_Text_Summarization.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Credentials:\n",
    "    def __init__(\n",
    "        self,\n",
    "        secrets_filepath = SECRETS_FILE_PATH):\n",
    "        \n",
    "\n",
    "        self.secret= read_yaml(secrets_filepath)\n",
    "    \n",
    "    def get_mlflow_tracking_credentials(self) -> CredentialsConfig:\n",
    "        secret = self.secret\n",
    "        \n",
    "        model_evaluation_config = CredentialsConfig(\n",
    "            MLFLOW_TRACKING_URI=self.secret.MLFLOW_TRACKING_URI,\n",
    "            MLFLOW_TRACKING_USERNAME=self.secret.MLFLOW_TRACKING_USERNAME,\n",
    "            MLFLOW_TRACKING_PASSWORD = self.secret.MLFLOW_TRACKING_PASSWORD                  \n",
    "           \n",
    "        )\n",
    "        return {\n",
    "            \"MLFLOW_TRACKING_URI\": model_evaluation_config.MLFLOW_TRACKING_URI,\n",
    "            \"MLFLOW_TRACKING_USERNAME\": model_evaluation_config.MLFLOW_TRACKING_USERNAME,\n",
    "            \"MLFLOW_TRACKING_PASSWORD\": model_evaluation_config.MLFLOW_TRACKING_PASSWORD\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-09 13:44:26,480: INFO: common: yaml file: secrets.yaml loaded successfully]\n"
     ]
    }
   ],
   "source": [
    "credentials = Credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_credentials = credentials.get_mlflow_tracking_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = mlflow_credentials[\"MLFLOW_TRACKING_URI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = mlflow_credentials[\"MLFLOW_TRACKING_USERNAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = mlflow_credentials[\"MLFLOW_TRACKING_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=\"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    params: dict\n",
    "    tokenizer_path: Path\n",
    "    metric_file_name: Path\n",
    "    mlflow_uri: str\n",
    "    experiment_name: str\n",
    "    model_path_packed: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlops_NLP_Text_Summarization.constants import *\n",
    "from mlops_NLP_Text_Summarization.utils.common import read_yaml, create_directories, save_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        secrets_filepath = SECRETS_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH\n",
    "        ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.secrets = read_yaml(secrets_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.TrainingArguments\n",
    "        secrets = self.secrets\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_path = config.model_path,\n",
    "            tokenizer_path = config.tokenizer_path,\n",
    "            params = params,            \n",
    "            metric_file_name = config.metric_file_name,\n",
    "            mlflow_uri = secrets.MLFLOW_TRACKING_URI,\n",
    "            experiment_name=config.experiment_name,\n",
    "            model_path_packed= config.model_path_packed,\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk, load_metric\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import joblib\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def generate_batch_sized_chunks(self,list_of_elements, batch_size):\n",
    "        \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "        Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "        for i in range(0, len(list_of_elements), batch_size):\n",
    "            yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "    \n",
    "    def calculate_metric_on_test_ds(self,dataset, metric, model, tokenizer, \n",
    "                               batch_size=16, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", \n",
    "                               column_text=\"article\", \n",
    "                               column_summary=\"highlights\"):\n",
    "        article_batches = list(self.generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "        target_batches = list(self.generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "        for article_batch, target_batch in tqdm(\n",
    "            zip(article_batches, target_batches), total=len(article_batches)):\n",
    "            \n",
    "            inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n",
    "                            padding=\"max_length\", return_tensors=\"pt\")\n",
    "            \n",
    "            summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                            attention_mask=inputs[\"attention_mask\"].to(device), \n",
    "                            length_penalty=0.8, num_beams=8, max_length=128)\n",
    "            ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
    "            \n",
    "            # Finally, we decode the generated texts, \n",
    "            # replace the  token, and add the decoded texts with the references to the metric.\n",
    "            decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n",
    "                                    clean_up_tokenization_spaces=True) \n",
    "                for s in summaries]      \n",
    "            \n",
    "            decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "            \n",
    "            \n",
    "            metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "            \n",
    "        #  Finally compute and return the ROUGE scores.\n",
    "        score = metric.compute()\n",
    "        return score\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_path).to(device)\n",
    "       \n",
    "        #loading data \n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "        \n",
    "\n",
    "        #name of experiment\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "\n",
    "        mlflow.set_experiment(self.config.experiment_name)\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        def get_experiment_id(name):\n",
    "            exp = mlflow.get_experiment_by_name(name)\n",
    "            if exp is None:\n",
    "                exp_id = mlflow.create_experiment(name)\n",
    "                return exp_id\n",
    "            return exp.experiment_id\n",
    "\n",
    "        \n",
    "        def get_last_run_id(exp_name):\n",
    "            exp = get_experiment_id(exp_name)\n",
    "            client = mlflow.MlflowClient()\n",
    "            runs = client.search_runs(experiment_ids=exp)\n",
    "            if len(runs) == 0:\n",
    "                return None\n",
    "            last_run = runs[0]\n",
    "            return last_run.info.run_id\n",
    "\n",
    "            run_id = get_last_run_id(self.config.experiment_name)\n",
    "            print(run_id)\n",
    "            os.environ[sys.argv[1]] = run_id\n",
    "            print(f'Saving {run_id} to environment variable {sys.argv[1]}')\n",
    "\n",
    "            run_id = os.environ[sys.argv[1]]\n",
    "      \n",
    "\n",
    "# Select a name for the model to be registered\n",
    "\n",
    "\n",
    "        \n",
    "        with mlflow.start_run(run_name=self.config.experiment_name):\n",
    "\n",
    "            run_id = get_last_run_id(self.config.experiment_name)\n",
    "\n",
    "            subpath = \"text_summarization\"\n",
    "\n",
    "            model_name = \"samsum_pegasus_model\"\n",
    "\n",
    "            # build the run URI\n",
    "            run_uri = f'runs:/{run_id}/{subpath}'\n",
    "\n",
    "            # register the model\n",
    "            \n",
    "\n",
    "\n",
    "            rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "    \n",
    "            rouge_metric = load_metric('rouge')\n",
    "\n",
    "            score = self.calculate_metric_on_test_ds(\n",
    "            dataset_samsum_pt['test'][0:10], rouge_metric, model_pegasus, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
    "                )\n",
    "            \n",
    "            rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "            \n",
    "\n",
    "            print(rouge_dict)\n",
    "            #df = pd.DataFrame(rouge_dict, index = ['pegasus'] )\n",
    "            \n",
    "            \n",
    "            save_json(path=Path(self.config.metric_file_name), data=rouge_dict)\n",
    "            mlflow.log_params(self.config.params)\n",
    "            mlflow.log_metric('rouge1', rouge_dict['rouge1'])\n",
    "            mlflow.log_metric('rouge2', rouge_dict['rouge2'])\n",
    "            mlflow.log_metric('rougeL', rouge_dict['rougeL'])\n",
    "            mlflow.log_metric('rougeLsum', rouge_dict['rougeLsum'])\n",
    "\n",
    "            model_version = mlflow.register_model(run_uri, model_name)\n",
    "\n",
    "\n",
    "        if tracking_url_type_store != \"file\":\n",
    "            mlflow.pytorch.log_model(model_pegasus, artifact_path= self.config.model_path, registered_model_name=\"samsum_pegasus_model_reg_name\")\n",
    "        else:\n",
    "            print( \"logging model to local file\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    #def log_into_mlflow(self):\n",
    "\n",
    "#keras_model=model,\n",
    "#                       artifact_path=MODELS_DIR,\n",
    "#                       registered_model_name=\"Ultimate Mario Model\")\n",
    "#        \n",
    "        \n",
    "\n",
    "        #with open(self.config.metric_file_name, \"r\") as f:\n",
    "        #    data = f.readlines()\n",
    "#\n",
    "        #for line in data:\n",
    "        #    line = line.strip()\n",
    "        #    values = line.split(\",\")\n",
    "        #    if len(values) == 2:\n",
    "        #        metric_name, metric_value = values\n",
    "        #        mlflow.log_metric(metric_name, float(metric_value))\n",
    "        #        \n",
    "        #mlflow.log_artifact(self.config.metric_file_name)\n",
    "#\n",
    "        #with open(\"params.yaml\", \"r\") as f:\n",
    "        #    params = yaml.safe_load(f)\n",
    "        #    \n",
    "        #mlflow.end_run()\n",
    "        #with mlflow.start_run():\n",
    "        #    mlflow.log_params(params)\n",
    "        #    self.evaluate()\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-09 15:02:42,963: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-08-09 15:02:42,967: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-08-09 15:02:42,969: INFO: common: yaml file: secrets.yaml loaded successfully]\n",
      "[2023-08-09 15:02:42,970: INFO: common: created directory at: artifacts]\n",
      "[2023-08-09 15:02:42,971: INFO: common: created directory at: artifacts/model_evaluation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/09 15:02:53 INFO mlflow.tracking.fluent: Experiment with name 'pegasus-samsum-model_test' does not exist. Creating a new experiment.\n",
      "100%|██████████| 5/5 [02:16<00:00, 27.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-09 15:05:12,025: INFO: rouge_scorer: Using default tokenizer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.02185158469332997, 'rouge2': 0.0, 'rougeL': 0.021873432881271068, 'rougeLsum': 0.021867135284620094}\n",
      "[2023-08-09 15:05:12,244: INFO: common: json file saved at: artifacts\\model_evaluation\\metrics.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'samsum_pegasus_model' already exists. Creating a new version of this model...\n",
      "2023/08/09 15:05:13 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: samsum_pegasus_model, version 8\n",
      "Created version '8' of model 'samsum_pegasus_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-09 15:17:47,157: WARNING: connectionpool: Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='dagshub.com', port=443): Read timed out. (read timeout=120)\")': /Nkifor/mlops-nlp-text-summarizer.mlflow/api/2.0/mlflow-artifacts/artifacts/7c3315d8806244699f2dddb8e4262f96/bbaf84c16a4b4f5084201bbdef8dfc71/artifacts/artifacts/model_training/pegasus-samsum-model/data/model.pth]\n",
      "[2023-08-09 15:30:08,229: WARNING: connectionpool: Retrying (Retry(total=3, connect=5, read=3, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='dagshub.com', port=443): Read timed out. (read timeout=120)\")': /Nkifor/mlops-nlp-text-summarizer.mlflow/api/2.0/mlflow-artifacts/artifacts/7c3315d8806244699f2dddb8e4262f96/bbaf84c16a4b4f5084201bbdef8dfc71/artifacts/artifacts/model_training/pegasus-samsum-model/data/model.pth]\n",
      "[2023-08-09 15:42:33,616: WARNING: connectionpool: Retrying (Retry(total=2, connect=5, read=2, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='dagshub.com', port=443): Read timed out. (read timeout=120)\")': /Nkifor/mlops-nlp-text-summarizer.mlflow/api/2.0/mlflow-artifacts/artifacts/7c3315d8806244699f2dddb8e4262f96/bbaf84c16a4b4f5084201bbdef8dfc71/artifacts/artifacts/model_training/pegasus-samsum-model/data/model.pth]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     model_evaluation_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_model_evaluation_config()\n\u001b[0;32m      4\u001b[0m     model_evaluation_config \u001b[39m=\u001b[39m ModelEvaluation(config\u001b[39m=\u001b[39mmodel_evaluation_config)\n\u001b[1;32m----> 5\u001b[0m     model_evaluation_config\u001b[39m.\u001b[39;49mevaluate()    \n\u001b[0;32m      6\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m      7\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[24], line 138\u001b[0m, in \u001b[0;36mModelEvaluation.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m     model_version \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mregister_model(run_uri, model_name)\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m tracking_url_type_store \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m     mlflow\u001b[39m.\u001b[39;49mpytorch\u001b[39m.\u001b[39;49mlog_model(model_pegasus, artifact_path\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmodel_path, registered_model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msamsum_pegasus_model_reg_name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[39mprint\u001b[39m( \u001b[39m\"\u001b[39m\u001b[39mlogging model to local file\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\pytorch\\__init__.py:293\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(pytorch_model, artifact_path, conda_env, code_paths, pickle_module, registered_model_name, signature, input_example, await_registration_for, requirements_file, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39mLog a PyTorch model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39m    PyTorch logged models\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m pickle_module \u001b[39m=\u001b[39m pickle_module \u001b[39mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[1;32m--> 293\u001b[0m \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[0;32m    294\u001b[0m     artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[0;32m    295\u001b[0m     flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49mpytorch,\n\u001b[0;32m    296\u001b[0m     pytorch_model\u001b[39m=\u001b[39;49mpytorch_model,\n\u001b[0;32m    297\u001b[0m     conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[0;32m    298\u001b[0m     code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[0;32m    299\u001b[0m     pickle_module\u001b[39m=\u001b[39;49mpickle_module,\n\u001b[0;32m    300\u001b[0m     registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[0;32m    301\u001b[0m     signature\u001b[39m=\u001b[39;49msignature,\n\u001b[0;32m    302\u001b[0m     input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[0;32m    303\u001b[0m     await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[0;32m    304\u001b[0m     requirements_file\u001b[39m=\u001b[39;49mrequirements_file,\n\u001b[0;32m    305\u001b[0m     extra_files\u001b[39m=\u001b[39;49mextra_files,\n\u001b[0;32m    306\u001b[0m     pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[0;32m    307\u001b[0m     extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[0;32m    308\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    309\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    310\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\models\\model.py:573\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m     _logger\u001b[39m.\u001b[39mwarning(_LOG_MODEL_MISSING_SIGNATURE_WARNING)\n\u001b[0;32m    572\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 573\u001b[0m mlflow\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mfluent\u001b[39m.\u001b[39;49mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39;49martifact_path)\n\u001b[0;32m    574\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_record_logged_model(mlflow_model)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\tracking\\fluent.py:911\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[1;34m(local_dir, artifact_path)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[39m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    910\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[1;32m--> 911\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\tracking\\client.py:1137\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[1;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\n\u001b[0;32m   1094\u001b[0m     \u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, local_dir: \u001b[39mstr\u001b[39m, artifact_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39m        is_dir: True\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:465\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[1;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_dir, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    459\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \n\u001b[0;32m    462\u001b[0m \u001b[39m    :param local_dir: Path to the directory of files to write.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_artifact_repo(run_id)\u001b[39m.\u001b[39;49mlog_artifacts(local_dir, artifact_path)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\store\\artifact\\http_artifact_repo.py:45\u001b[0m, in \u001b[0;36mHttpArtifactRepository.log_artifacts\u001b[1;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[0;32m     41\u001b[0m     artifact_dir \u001b[39m=\u001b[39m (\n\u001b[0;32m     42\u001b[0m         posixpath\u001b[39m.\u001b[39mjoin(artifact_path, rel_path) \u001b[39mif\u001b[39;00m artifact_path \u001b[39melse\u001b[39;00m rel_path\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m filenames:\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_artifact(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, f), artifact_dir)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\store\\artifact\\http_artifact_repo.py:28\u001b[0m, in \u001b[0;36mHttpArtifactRepository.log_artifact\u001b[1;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m extra_headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m: mime_type}\n\u001b[0;32m     27\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(local_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> 28\u001b[0m     resp \u001b[39m=\u001b[39m http_request(\n\u001b[0;32m     29\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_host_creds, endpoint, \u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, data\u001b[39m=\u001b[39;49mf, extra_headers\u001b[39m=\u001b[39;49mextra_headers\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m     augmented_raise_for_status(resp)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:93\u001b[0m, in \u001b[0;36mhttp_request\u001b[1;34m(host_creds, endpoint, method, max_retries, backoff_factor, extra_headers, retry_codes, timeout, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcleaned_hostname\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_http_response_with_retries(\n\u001b[0;32m     94\u001b[0m         method,\n\u001b[0;32m     95\u001b[0m         url,\n\u001b[0;32m     96\u001b[0m         max_retries,\n\u001b[0;32m     97\u001b[0m         backoff_factor,\n\u001b[0;32m     98\u001b[0m         retry_codes,\n\u001b[0;32m     99\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    100\u001b[0m         verify\u001b[39m=\u001b[39;49mhost_creds\u001b[39m.\u001b[39;49mverify,\n\u001b[0;32m    101\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    102\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    103\u001b[0m     )\n\u001b[0;32m    104\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m to:\n\u001b[0;32m    105\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    106\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m failed with timeout exception \u001b[39m\u001b[39m{\u001b[39;00mto\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m To increase the timeout, set the environment variable \u001b[39m\u001b[39m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m to a larger value.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mto\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\mlflow\\utils\\request_utils.py:131\u001b[0m, in \u001b[0;36m_get_http_response_with_retries\u001b[1;34m(method, url, max_retries, backoff_factor, retry_codes, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39mPerforms an HTTP request using Python's `requests` module with an automatic retry policy.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39m:return: requests.Response object.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m session \u001b[39m=\u001b[39m _get_request_session(max_retries, backoff_factor, retry_codes)\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\urllib3\\connectionpool.py:826\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[0;32m    822\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    824\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[0;32m    825\u001b[0m     )\n\u001b[1;32m--> 826\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    827\u001b[0m         method,\n\u001b[0;32m    828\u001b[0m         url,\n\u001b[0;32m    829\u001b[0m         body,\n\u001b[0;32m    830\u001b[0m         headers,\n\u001b[0;32m    831\u001b[0m         retries,\n\u001b[0;32m    832\u001b[0m         redirect,\n\u001b[0;32m    833\u001b[0m         assert_same_host,\n\u001b[0;32m    834\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    835\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    836\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    837\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    838\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    839\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    843\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\urllib3\\connectionpool.py:826\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[0;32m    822\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    824\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[0;32m    825\u001b[0m     )\n\u001b[1;32m--> 826\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    827\u001b[0m         method,\n\u001b[0;32m    828\u001b[0m         url,\n\u001b[0;32m    829\u001b[0m         body,\n\u001b[0;32m    830\u001b[0m         headers,\n\u001b[0;32m    831\u001b[0m         retries,\n\u001b[0;32m    832\u001b[0m         redirect,\n\u001b[0;32m    833\u001b[0m         assert_same_host,\n\u001b[0;32m    834\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    835\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    836\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    837\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    838\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    839\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    843\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\urllib3\\connectionpool.py:826\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[0;32m    822\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    824\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[0;32m    825\u001b[0m     )\n\u001b[1;32m--> 826\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    827\u001b[0m         method,\n\u001b[0;32m    828\u001b[0m         url,\n\u001b[0;32m    829\u001b[0m         body,\n\u001b[0;32m    830\u001b[0m         headers,\n\u001b[0;32m    831\u001b[0m         retries,\n\u001b[0;32m    832\u001b[0m         redirect,\n\u001b[0;32m    833\u001b[0m         assert_same_host,\n\u001b[0;32m    834\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    835\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    836\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    837\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    838\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    839\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    840\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    843\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\urllib3\\connectionpool.py:415\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    413\u001b[0m         conn\u001b[39m.\u001b[39mrequest_chunked(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    414\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[0;32m    417\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (six\u001b[39m.\u001b[39mensure_str(k\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m headers):\n\u001b[0;32m    243\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[0;32m   1254\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1255\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1299\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\http\\client.py:1050\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mif\u001b[39;00m encode_chunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_http_vsn \u001b[39m==\u001b[39m \u001b[39m11\u001b[39m:\n\u001b[0;32m   1047\u001b[0m         \u001b[39m# chunked encoding\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m         chunk \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(chunk)\u001b[39m:\u001b[39;00m\u001b[39mX\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mascii\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m chunk \\\n\u001b[0;32m   1049\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1050\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(chunk)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m encode_chunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_http_vsn \u001b[39m==\u001b[39m \u001b[39m11\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[39m# end chunked transfer\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\http\\client.py:972\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    970\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock\u001b[39m.\u001b[39;49msendall(data)\n\u001b[0;32m    973\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mIterable):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\ssl.py:1204\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         amount \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(byte_view)\n\u001b[0;32m   1203\u001b[0m         \u001b[39mwhile\u001b[39;00m count \u001b[39m<\u001b[39m amount:\n\u001b[1;32m-> 1204\u001b[0m             v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(byte_view[count:])\n\u001b[0;32m   1205\u001b[0m             count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m v\n\u001b[0;32m   1206\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\mlops\\lib\\ssl.py:1173\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1170\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1171\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1172\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1173\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mwrite(data)\n\u001b[0;32m   1174\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msend(data, flags)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation_config.evaluate()    \n",
    "except Exception as e:\n",
    "    raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
